{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7be11603-5634-4276-9b49-1276b6710330",
   "metadata": {},
   "source": [
    "# Potential Talents - An Apziva Project (#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de81d9f-0a9d-456f-a356-8d780ee8faba",
   "metadata": {},
   "source": [
    "By Samuel Alter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a65b755-455b-4e5f-ac83-c4cddd4106fe",
   "metadata": {},
   "source": [
    "Apziva: 6bImatZVlK6DnbEo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aea5eb-6509-4ac6-9f5d-2cb70ac12f72",
   "metadata": {},
   "source": [
    "# Proceed to the [previous notebook](potential_talents_pt2_ranknet.ipynb) to view my work on RankNet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a455e2f6-9a52-405f-b58f-2ecf05d14ebb",
   "metadata": {},
   "source": [
    "## Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297719bf-96f1-4348-848b-81b1c7e7efc0",
   "metadata": {},
   "source": [
    "We are working with a talent sourcing and management company to help them surface candidates that are a best fit for their human resources job post. We are using a dataset of job candidates' job titles, their location, and their number of LinkedIn connections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d86ba17-4965-4b51-95b8-028ff4e3079a",
   "metadata": {},
   "source": [
    "### Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e8349a-b08e-4050-b332-098c25ed8d98",
   "metadata": {},
   "source": [
    "Produce a probability, between 0 and 1, of how closely the candidate fits the job description of **\"Aspiring human resources\"** or **\"Seeking human resources.\"** After an initial recommendation pulls out a candidate(s) to be starred for future consideration, the recommendation will be re-run and new \"stars\" will be awarded.\n",
    "\n",
    "To help predict how the candidates fit, we are tracking the performance of two success metrics:\n",
    "* Rank candidates based on a fitness score\n",
    "* Re-rank candidates when a candidate is starred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6acd81-fec4-4931-9bae-4c56c18742c7",
   "metadata": {},
   "source": [
    "We also need to do the following:\n",
    "* Explain how the algorithm works and how the ranking improves after each starring iteration\n",
    "* How to filter out candidates which should not be considered at all\n",
    "* Determine a cut-off point (if possible) that would work for other roles without losing high-potential candidates\n",
    "* Ideas to explore on automating this procedure to reduce or eliminate human bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b1272d-f942-4c06-b5db-c0ff5055c238",
   "metadata": {},
   "source": [
    "### The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d10ab64-f049-4e39-b393-1f392f844600",
   "metadata": {},
   "source": [
    "| Column | Data Type | Comments |\n",
    "|---|---|---|\n",
    "| `id` | Numeric | Unique identifier for the candidate |\n",
    "| `job_title` | Text | Job title for the candidate |\n",
    "| `location` | Text | Geographic location of the candidate |\n",
    "| `connections` | Text | Number of LinkedIn connections for the candidate |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc76c1ee-15a9-451e-88f3-1313cd98c2a0",
   "metadata": {},
   "source": [
    "Connections over 500 are encoded as \"500+\". Some do not have specific locations listed and just had their country, so I substituted capitol cities or geographic centers to represent those countries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474e78ad-e88f-4353-be66-055b89a201a8",
   "metadata": {},
   "source": [
    "# Imports and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cef80551-83b8-4a14-b77f-02b510efd1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to install pandas, use\n",
    "# pip install 'lightgbm[pandas]'\n",
    "# or\n",
    "# pip install 'lightgbm[scikit-learn]'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "import torch\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dca60ee-69a7-49b0-8e3f-a1f9a1eb4f5b",
   "metadata": {},
   "source": [
    "# LambdaRank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19a1670-2688-4b1d-8a6e-56dedee89a69",
   "metadata": {},
   "source": [
    "In an effort to explore other ranking algorithms, we will now turn to LambdaRank. It is an evolution of the RankNet algorithm that we worked on above. While RankNet looks to optimize pairwise accuracy, LambdaRank optimizes for ranking metrics like NDCG, or Normalized Discounted Cumulative Gain. This checks not only if the first item should be ranked higher than the second, but also how much swapping their order would improve the final ranking. The gain can be thought of this way: if a relevant item is placed close to the top, it will have a greater gain than if a relevant item was placed towards the bottom. RankNet also takes advantage of a loss function and cares about individual rankings, while LambdaRank uses **lambdas** that help adjust the model's focus to help improve the overall ranking quality.\n",
    "\n",
    "You can read more about LambdaRank [here](https://tamaracucumides.medium.com/learning-to-rank-with-lightgbm-code-example-in-python-843bd7b44574). There's a short snippet of information about LambdaRank [from Microsoft](https://www.microsoft.com/en-us/research/publication/from-ranknet-to-lambdarank-to-lambdamart-an-overview/). Researchers there designed the algorithm.\n",
    "\n",
    "[This repository](https://github.com/Ransaka/LTR-with-LIghtGBM) gives a good example of how to implement the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c03ed791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2870"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get random seed from project\n",
    "with open('seed.txt', 'r') as file:\n",
    "    seed = int(file.read())\n",
    "    \n",
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f322ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 104 embeddings. First element type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# load the job title data\n",
    "loaded_data = np.load('../joblib/3_job_title.npz', allow_pickle=True)\n",
    "job_title_sbert = [np.array(embedding) for embedding in loaded_data['embeddings']]\n",
    "print(f\"Loaded {len(job_title_sbert)} embeddings. First element type: {type(job_title_sbert[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c7c9b1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert back to tensors\n",
    "job_title_tensors = [torch.tensor(embedding) for embedding in job_title_sbert]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4c96a998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-7.1764e-02,  2.2637e-03, -1.7858e-02,  3.1808e-02,  8.6310e-03,\n",
       "         4.5645e-02, -6.7703e-02,  3.1216e-02,  1.8814e-02, -3.6150e-04,\n",
       "        -1.5786e-02, -3.0461e-02, -8.2910e-02, -5.0705e-02, -7.0172e-02,\n",
       "         3.2520e-02,  9.6550e-03, -8.0883e-02,  4.6644e-02, -3.8407e-02,\n",
       "         2.3128e-02,  3.6828e-02, -1.5138e-03, -9.5810e-02, -2.7337e-02,\n",
       "        -3.0467e-02, -1.6989e-02, -2.4439e-02, -2.1443e-04, -3.0366e-03,\n",
       "         1.0420e-02,  5.6600e-03,  2.4441e-02,  3.2096e-02,  6.2465e-02,\n",
       "         6.9278e-02,  4.4225e-02, -1.1663e-02,  1.5852e-01,  3.1511e-02,\n",
       "        -9.2587e-03, -8.1887e-02, -2.8538e-02,  3.3625e-02, -6.5775e-03,\n",
       "        -5.9914e-02,  2.1527e-02, -3.0205e-02,  3.8459e-02, -8.4312e-03,\n",
       "        -7.3194e-02, -6.0277e-02,  3.9353e-02, -4.5725e-02,  2.8139e-02,\n",
       "         3.0143e-02,  2.7823e-02, -1.5330e-02,  6.5976e-03, -6.2322e-02,\n",
       "        -1.5916e-02, -3.1975e-02,  2.1324e-02,  3.4776e-02,  8.1722e-02,\n",
       "         5.2771e-03, -5.2103e-02,  2.3793e-02,  3.8527e-02, -8.8017e-02,\n",
       "        -2.9698e-02, -1.1102e-02, -3.9710e-02,  1.3897e-02,  9.4293e-02,\n",
       "         2.3786e-02, -3.9860e-03,  2.4895e-02,  5.4456e-02,  2.3790e-02,\n",
       "         4.8017e-02,  6.9421e-02, -4.3053e-02,  3.7367e-02, -8.3389e-02,\n",
       "        -3.9554e-02, -3.0625e-02,  1.4594e-02,  6.1105e-03,  6.1274e-02,\n",
       "         8.6866e-03, -4.0442e-02,  1.2885e-02, -1.1718e-03, -8.1843e-02,\n",
       "         1.4024e-02, -9.5660e-02,  4.8773e-02,  1.6119e-02,  4.4493e-03,\n",
       "        -7.3601e-02,  7.6218e-02, -3.8007e-02,  1.9535e-02,  6.1472e-03,\n",
       "         1.6961e-02,  3.5967e-02,  9.7436e-03,  7.1682e-02,  3.1386e-02,\n",
       "        -1.4554e-02, -1.5890e-02, -8.2825e-02, -1.6305e-02,  9.7006e-03,\n",
       "         2.5257e-02,  2.6843e-04,  4.0493e-02,  9.2181e-02, -1.9046e-03,\n",
       "         2.7567e-02,  5.1132e-02, -7.3212e-02, -6.3115e-02, -7.9823e-03,\n",
       "        -1.6765e-01, -2.9606e-02, -1.3230e-33,  3.2905e-03,  9.4100e-02,\n",
       "         4.6308e-02,  7.4895e-02, -4.0938e-02, -2.2898e-02, -6.1546e-02,\n",
       "         2.3439e-02, -1.0703e-02,  5.7815e-02, -2.7025e-02,  1.0929e-01,\n",
       "        -3.5596e-02,  2.7121e-02, -4.3518e-02, -4.2956e-02, -3.6647e-02,\n",
       "         2.7006e-02, -3.4044e-03,  7.2917e-02,  3.3263e-02,  4.0946e-02,\n",
       "        -4.9946e-03, -8.9749e-02, -1.0261e-02, -1.5499e-03,  6.4816e-02,\n",
       "        -6.7815e-03,  8.4745e-02,  2.1064e-02,  8.4459e-03,  1.2042e-02,\n",
       "        -6.5129e-02, -8.5254e-02,  5.0156e-02, -1.5025e-02, -1.4243e-01,\n",
       "        -1.0929e-02,  1.9596e-02, -1.6974e-02, -7.1898e-02,  1.1936e-01,\n",
       "         2.8736e-02, -1.6113e-03,  1.6926e-02,  2.1461e-02,  1.4876e-01,\n",
       "         6.5798e-02,  7.5223e-02, -3.7247e-02, -8.2096e-02, -8.9025e-02,\n",
       "         6.3531e-03, -3.5823e-02,  6.1774e-02, -5.0907e-02,  2.2478e-03,\n",
       "         5.0267e-02, -4.2082e-02,  4.7737e-02,  1.1122e-03,  4.1247e-02,\n",
       "        -6.6179e-02,  1.2616e-02, -3.4835e-02, -6.5496e-02, -2.0065e-02,\n",
       "        -2.4050e-03,  1.2752e-01, -3.3548e-02,  2.9069e-03,  6.0244e-03,\n",
       "         3.8790e-02, -1.9889e-02, -5.2084e-02,  1.3556e-02,  7.4122e-02,\n",
       "        -1.8150e-02,  4.5881e-02, -7.6674e-02, -1.6397e-02,  1.6860e-02,\n",
       "         7.5554e-02, -4.5430e-02,  4.6240e-02,  1.8891e-02,  4.6056e-02,\n",
       "        -5.3356e-02, -4.7187e-03,  1.7231e-02,  3.8095e-02, -4.6275e-02,\n",
       "        -2.7911e-02,  9.9471e-02, -5.3039e-02, -1.0890e-33,  1.2991e-01,\n",
       "        -6.4036e-03,  1.3858e-02, -8.2864e-02,  1.8651e-02,  6.8433e-02,\n",
       "         8.3629e-02,  6.6377e-02, -3.1906e-02, -1.8682e-03,  9.4951e-02,\n",
       "        -3.6740e-02, -2.0478e-02,  5.3023e-02,  2.5670e-02,  1.9433e-03,\n",
       "         6.3942e-03, -5.0238e-02, -1.0762e-01, -2.8480e-02,  7.8596e-04,\n",
       "         6.8429e-02, -9.8799e-03,  1.7832e-02,  1.0214e-03,  3.7320e-03,\n",
       "         3.1418e-02,  6.1013e-02, -7.1873e-02,  1.2601e-02,  1.3720e-02,\n",
       "         5.5045e-03, -4.4870e-02,  3.1552e-02,  1.1152e-03, -1.6330e-03,\n",
       "         6.8587e-02,  3.1625e-02,  4.3843e-02,  4.3220e-02,  7.8730e-02,\n",
       "        -7.7897e-02, -8.3744e-02, -4.3730e-02,  3.0119e-02, -3.9756e-02,\n",
       "        -1.5743e-02, -3.4585e-02,  1.8032e-02, -1.9825e-02, -3.1881e-02,\n",
       "        -4.9710e-02, -3.1258e-02, -1.5903e-02,  7.6570e-02,  2.3777e-02,\n",
       "         3.9713e-02, -3.4791e-02, -2.0734e-02, -2.6111e-03,  7.7315e-03,\n",
       "         1.0448e-01,  5.8785e-02,  2.5375e-02, -3.9127e-02, -2.6788e-02,\n",
       "         1.2177e-02, -4.2029e-02, -6.9536e-02,  9.5341e-02,  1.7182e-02,\n",
       "         1.1030e-01, -8.1969e-04, -1.2397e-01, -7.1878e-02,  4.1063e-02,\n",
       "         4.0792e-02, -9.0983e-02, -5.9649e-02,  6.5373e-03, -1.1831e-01,\n",
       "        -8.6913e-03, -7.0987e-02,  9.2960e-02, -2.3609e-02,  5.2708e-02,\n",
       "         5.3937e-02, -5.7072e-02,  1.0236e-03, -5.9659e-02, -6.0416e-02,\n",
       "        -2.0895e-02,  2.1713e-02, -2.0009e-02, -4.3782e-02, -2.4745e-08,\n",
       "        -3.3255e-02,  8.0088e-02, -5.9178e-02,  1.0442e-02, -1.7130e-02,\n",
       "         2.3009e-02, -9.9112e-02, -7.1707e-02, -1.2053e-02,  1.4190e-02,\n",
       "        -2.8237e-02, -4.7716e-02, -4.1981e-02, -3.3464e-02,  1.9701e-02,\n",
       "        -1.0399e-02, -6.1938e-02,  1.4433e-02,  3.5326e-02, -5.9824e-02,\n",
       "         4.3243e-02, -1.9379e-02,  1.2675e-02,  3.3618e-02, -1.7182e-02,\n",
       "         2.0765e-02,  7.6451e-03, -2.7259e-02, -3.7614e-03,  4.3418e-02,\n",
       "         4.2219e-02, -7.9126e-03,  1.7400e-02, -7.2439e-02,  7.8125e-02,\n",
       "        -1.8242e-02, -3.9498e-02, -7.4762e-02, -4.0797e-03,  4.2082e-02,\n",
       "         4.2996e-02, -1.4236e-02, -5.9925e-02,  1.8145e-02,  1.1572e-01,\n",
       "         6.8947e-03, -1.6753e-02,  9.6921e-02, -1.1013e-02,  9.1657e-03,\n",
       "         3.7196e-02,  3.8204e-03, -1.3778e-01, -2.6175e-02,  3.4218e-02,\n",
       "         2.3139e-02,  1.7900e-02, -4.0268e-02, -1.0566e-01,  4.4295e-02,\n",
       "         5.3318e-02, -1.4526e-01, -2.5792e-02, -5.5173e-03])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "job_title_tensors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f6e6afd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# load candidate ID and rank data\n",
    "with open('../joblib/candidate_ids.pkl', 'rb') as f:\n",
    "    candidate_ids = pickle.load(f)\n",
    "\n",
    "with open('../joblib/ranks.pkl', 'rb') as f:\n",
    "    ranks = pickle.load(f)\n",
    "    \n",
    "print(\"Data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "676363c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "candidate_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ff495fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 2, 16]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "ranks[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8a5eced7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "pairs = []\n",
    "labels = []\n",
    "id_pairs = [] # to store pairs of IDs\n",
    "\n",
    "for (i, j) in itertools.combinations(range(len(job_titles)), 2):\n",
    "    id_i, id_j = candidate_ids[i], candidate_ids[j]\n",
    "    job_i, job_j = job_titles[i], job_titles[j]\n",
    "    rank_i, rank_j = ranks[i], ranks[j]\n",
    "\n",
    "    # label: 1 if job_i is ranked better, else 0\n",
    "    label = 1 if rank_i < rank_j else 0\n",
    "\n",
    "    # append to lists and ensure tensors are cloned properly\n",
    "    pairs.append((job_i.clone().detach().requires_grad_(True), job_j.clone().detach().requires_grad_(True)))\n",
    "    labels.append(label)\n",
    "    id_pairs.append((id_i, id_j))  # store the ID pair\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "88811573-98c6-4bc2-b46f-9f4433079dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished defining train_data. Shape: (3213, 5)\n",
      "Finished defining test_data. Shape: (1072, 5)\n"
     ]
    }
   ],
   "source": [
    "## we'll include a validation set for this run\n",
    "# split data into training+validation and testing sets\n",
    "pairs_train_val, pairs_test, labels_train_val, labels_test, id_pairs_train_val, id_pairs_test = train_test_split(\n",
    "    pairs, labels, id_pairs, test_size=0.2, random_state=seed\n",
    ")\n",
    "\n",
    "# split val set into training and validation sets\n",
    "pairs_train, pairs_val, labels_train, labels_val, id_pairs_train, id_pairs_val = train_test_split(\n",
    "    pairs_train_val, labels_train_val, id_pairs_train_val, test_size=0.25, random_state=seed\n",
    ")  # 0.25 x (1.0 - test_size) = 0.2, so validation set is 20% of the original data\n",
    "\n",
    "# convert to DataFrame for saving to parquet\n",
    "train_data = pd.DataFrame({\n",
    "    'input_1': [pair[0].detach().cpu().numpy() for pair in pairs_train],\n",
    "    'input_2': [pair[1].detach().cpu().numpy() for pair in pairs_train],\n",
    "    'label': labels_train,\n",
    "    'id_1': [id_pair[0] for id_pair in id_pairs_train],\n",
    "    'id_2': [id_pair[1] for id_pair in id_pairs_train],\n",
    "})\n",
    "print(f'Finished defining train_data. Shape: {train_data.shape}')\n",
    "\n",
    "test_data = pd.DataFrame({\n",
    "    'input_1': [pair[0].detach().cpu().numpy() for pair in pairs_test],\n",
    "    'input_2': [pair[1].detach().cpu().numpy() for pair in pairs_test],\n",
    "    'label': labels_test,\n",
    "    'id_1': [id_pair[0] for id_pair in id_pairs_test],\n",
    "    'id_2': [id_pair[1] for id_pair in id_pairs_test],\n",
    "})\n",
    "print(f'Finished defining test_data. Shape: {test_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac23291-deff-481a-b428-23633a2309ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate Learning To Rank'er with LightGBM\n",
    "ranker = lgb.LGBMRanker()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apziva_3lgb",
   "language": "python",
   "name": "apziva_3lgb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
