{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "475321f8-27bd-413b-840f-59f203577e80",
   "metadata": {},
   "source": [
    "# Potential Talents - An Apziva Project (#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e4ffcd-3ebe-46dc-8f29-9ffec9c17dc2",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e779d93-dc3a-4e9c-bcaf-42a94f5056dd",
   "metadata": {},
   "source": [
    "By Samuel Alter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e52f988-ef83-4ecb-a5cf-b1a93556e117",
   "metadata": {},
   "source": [
    "Apziva: 6bImatZVlK6DnbEo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956a7d3d-a201-44bd-8123-eacaddcb4069",
   "metadata": {},
   "source": [
    "## Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874bf7ce-d1eb-4d45-9339-4821382b93d6",
   "metadata": {},
   "source": [
    "### Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884cf463-3b7c-461a-b094-9a5fd2182a6d",
   "metadata": {},
   "source": [
    "### The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621c288e-6e1b-4196-a318-984df113bd50",
   "metadata": {},
   "source": [
    "## Imports and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0b12ae9-b001-455b-a6be-e5221bc27e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import joblib\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "from pathlib import Path\n",
    "import inspect\n",
    "import re\n",
    "import string\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import geopandas as gpd\n",
    "import duckdb as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c90afd9-61d3-4aea-aa0f-763b43fbe9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords # lists of stopwords\n",
    "from nltk.tokenize import word_tokenize # tool for splitting documents into tokens\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import PorterStemmer # basic stemmer\n",
    "from nltk.stem import WordNetLemmatizer # more sophisticated word->lemma\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170bfeb6-f514-4a2e-a199-9096e22d3bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function to generate random integers\n",
    "\n",
    "def rand_gen(low=1,high=1e4):\n",
    "    '''\n",
    "    Generates a pseudo-random integer\n",
    "    consisting of up to four digits\n",
    "    '''\n",
    "    import numpy as np\n",
    "    rng=np.random.default_rng()\n",
    "    random_state=int(rng.integers(low=low,high=high))\n",
    "    \n",
    "    return random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbb28ab-89d8-4a7f-8f50-0ea55e9b25f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=rand_gen()\n",
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb9c656-48c3-41f1-9c89-df55993cde43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the randomness seed throughout the notebook\n",
    "# source: # https://odsc.medium.com/properly-setting-the-random-seed-in-ml-experiments-not-as-simple-as-you-might-imagine-219969c84752\n",
    "\n",
    "## set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "## set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed)\n",
    "## set `numpy` pseudo-random generator at a fixed value\n",
    "np.random.seed(seed)\n",
    "np.random.default_rng(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d210da9-c401-4db6-89b9-6b857e15047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variable_name(var):\n",
    "    callers_local_vars = inspect.currentframe().f_back.f_locals.items()\n",
    "    return [name for name, val in callers_local_vars if val is var]\n",
    "\n",
    "def fileDaterSaver(location: str,\n",
    "                   filetype: str,\n",
    "                   object_,\n",
    "                   extra: str = '',\n",
    "                   verbose: bool = True):\n",
    "\n",
    "    '''\n",
    "    Function that gets a timestamped filename and saves it\n",
    "    to a user-specified location.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    location: str - The location where the file will be saved.\n",
    "    filetype: str - The type of the file to save ('csv' or 'json').\n",
    "    object_: The object to be saved. Should be a pandas DataFrame\n",
    "        for 'csv' or serializable for 'json'.\n",
    "    extra: str - Additional string to include in the filename.\n",
    "    verbose: bool - Whether to print verbose messages.\n",
    "    '''\n",
    "\n",
    "    # get current date and time\n",
    "    current_datetime = datetime.now()\n",
    "\n",
    "    # print current date and time to check\n",
    "    if verbose:\n",
    "        print('current_datetime:', current_datetime)\n",
    "\n",
    "    # format the datetime for a filename\n",
    "    datetime_suffix = current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "    # create filename with the datetime suffix\n",
    "    if extra != '':\n",
    "        file_name = f'{location}{extra}_{datetime_suffix}.{filetype}'\n",
    "    else:\n",
    "        file_name = f'{location}{datetime_suffix}.{filetype}'\n",
    "\n",
    "    # print file name\n",
    "    if verbose:\n",
    "        print(file_name)\n",
    "\n",
    "    # save object\n",
    "    if filetype == 'csv':\n",
    "        object_.to_csv(file_name, index=True)\n",
    "    elif filetype == 'json':\n",
    "        with open(file_name, 'w') as file:\n",
    "            file.write(json.dumps(object_, default=str))\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Use 'csv' or 'json'.\")\n",
    "\n",
    "    # confirm save\n",
    "    file_path = Path(file_name)\n",
    "    if file_path.exists():\n",
    "        variable_name = get_variable_name(object_)\n",
    "        if variable_name:\n",
    "            print(f'Successfully saved {variable_name[0]} to {file_path}')\n",
    "        else:\n",
    "            print(f'Successfully saved object to {file_path}')\n",
    "    else:\n",
    "        print(\"File save error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad724e2-678c-44c4-8b40-6b7d28ccb048",
   "metadata": {},
   "source": [
    "Read in the datset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef457c21-9427-42fa-9fd0-6b117df7e480",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/3_data.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664da8f9-1cc8-42aa-b61f-345181cfd24c",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5588f3a3-79c7-4b53-a583-04b8b7db7e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2d80f3-65ac-4a80-9751-f60915032a60",
   "metadata": {},
   "source": [
    "No nulls in the dataset. That is nice for us! There are 104 total observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f950c4e7-492a-471c-b5e8-b216e7eceeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a878f527-ba5d-4b45-9a8e-6d67c39d3cbb",
   "metadata": {},
   "source": [
    "We'll remove `fit` as it is a column with no data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412b43a5-6dbd-442c-a426-ccff66bbecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'fit' in df.columns: # flow control for repeat code executions\n",
    "    df.drop('fit',axis=1,inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46792bc-1e61-4a52-bc54-a3e0c28a043a",
   "metadata": {},
   "source": [
    "Inspect the connections column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adbe8c8-5738-446b-b762-62f9fffcc2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "connections=df['connection'].value_counts()\n",
    "\n",
    "connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4770d59b-f145-42dc-a47a-d6c24cbec6e7",
   "metadata": {},
   "source": [
    "I will change the \"500+\" into 500 so that it can remain a numeric value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0db1256-fdaa-46d4-a893-e9444b0f0b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all non-numeric characters from the column\n",
    "column='connection'\n",
    "if not pd.api.types.is_numeric_dtype(df[column]):\n",
    "    df[column]=df[column].str.replace(r'\\D','',regex=True)\n",
    "\n",
    "    # check if any '+' characters are still present\n",
    "    print(\"Amount of '+' in column:\",df[column].str.contains(r'\\+').sum())\n",
    "\n",
    "    # convert to integer\n",
    "    df[column]=pd.to_numeric(df[column],errors='coerce')\n",
    "    print(df.dtypes)\n",
    "\n",
    "    # check if conversion was successful\n",
    "    print('\\nWas conversion successful?')\n",
    "    if pd.api.types.is_numeric_dtype(df[column]):\n",
    "        print('Yes.')\n",
    "    else:\n",
    "        print('No.')\n",
    "else:\n",
    "    print(f'There are no non-numeric characters in the column: {column}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b271ed-4f3b-41f7-a4b9-95ddf1a47e69",
   "metadata": {},
   "source": [
    "### Histogram of Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ec465a-c67b-4544-919a-451c2a50839f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the >500 connection observations\n",
    "df_no500=df[df['connection']<500]\n",
    "\n",
    "# check\n",
    "df_no500['connection'].value_counts().head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eccc7f-e585-43cd-b0d8-1e97564163fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(x=df_no500['connection'],\n",
    "         color='cornflowerblue',\n",
    "         bins=20)\n",
    "plt.title('Histogram of Connections\\n\\nNote:\\nThose with greater than 500 connections are not shown\\nThere are 44 observations with >500 connections')\n",
    "plt.xlabel('Number of Connections')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(which='both',axis='y')\n",
    "plt.xticks(range(0,501,50)) # get xticks to appear every 50 connections\n",
    "\n",
    "plt.savefig('figures/histogram_connections.pdf')\n",
    "plt.savefig('figures/histogram_connections.jpg')\n",
    "plt.savefig('figures/histogram_connections.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bc33a2-f2dd-4111-9c62-8dfc2c53ad7d",
   "metadata": {},
   "source": [
    "### Boxplot of Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaa166c-f90d-467a-a0cc-ffb3fca5e33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,2))\n",
    "sns.boxplot(x=df['connection'],color='cornflowerblue')\n",
    "plt.title('Boxplot of Connections\\nIncluding those with >500 Connections')\n",
    "plt.xlabel('Connection')\n",
    "plt.xticks(range(0,501,50))\n",
    "\n",
    "plt.savefig('figures/boxplot_connections.pdf')\n",
    "plt.savefig('figures/boxplot_connections.jpg')\n",
    "plt.savefig('figures/boxplot_connections.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a7afe5-f538-4803-b389-4cce71394d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,2))\n",
    "sns.boxplot(x=df_no500['connection'],color='cornflowerblue')\n",
    "plt.title('Boxplot of Connections\\nNot including those with >500 Connections')\n",
    "plt.xlabel('Connection')\n",
    "plt.xticks(range(0,501,50))\n",
    "\n",
    "plt.savefig('figures/boxplot_no500.pdf')\n",
    "plt.savefig('figures/boxplot_no500.jpg')\n",
    "plt.savefig('figures/boxplot_no500.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e30fbd6-d799-44fb-a344-aee21fe89280",
   "metadata": {},
   "source": [
    "### Map of Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed4eadc-0d7a-47bb-b6d2-14e6749ddc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bad7bd3-b0d7-4d0d-ace0-33a073f97932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique locations in dataset\n",
    "df['location'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0b11ee-741a-40be-9961-44e64d446750",
   "metadata": {},
   "source": [
    "This is not terrible. I'd like to get the centroids for each municipality to create a chloropleth map of the locations.\n",
    "\n",
    "First step is to clean this column to make it easier to get the centroids. We won't go fully intense with the geospatial information, so if the city says \"Greater CITY Area,\" I'll just make that the CITY to simplify things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60bb1c1-fad1-429d-a70e-37b49b38fe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_names_map={\n",
    "    'Kanada':'Canada'\n",
    "    'Raleigh-Durham, North Carolina Area':\n",
    "    'Houston, Texas Area'\n",
    "    'Greater New York City Area'\n",
    "    'Houston, Texas'\n",
    "    'Denton, Texas'\n",
    "    'San Francisco Bay Area'\n",
    "    'Greater Philadelphia Area'\n",
    "    'İzmir, Türkiye'\n",
    "    'Lake Forest, California'\n",
    "    'Atlanta, Georgia'\n",
    "    'Chicago, Illinois'\n",
    "    'Austin, Texas Area'\n",
    "    'Greater Atlanta Area'\n",
    "    'Amerika Birleşik Devletleri'\n",
    "    'Long Beach, California'\n",
    "    'Milpitas, California'\n",
    "    'Greater Chicago Area'\n",
    "    'Torrance, California'\n",
    "    'Greater Los Angeles Area'\n",
    "    'Bridgewater, Massachusetts'\n",
    "    'Lafayette, Indiana'\n",
    "    'Kokomo, Indiana Area'\n",
    "    'Las Vegas, Nevada Area'\n",
    "    'Cape Girardeau, Missouri'\n",
    "    'Gaithersburg, Maryland'\n",
    "    'Baltimore, Maryland'\n",
    "    'Dallas/Fort Worth Area'\n",
    "    'Highland, California'\n",
    "    'Los Angeles, California'\n",
    "    'Chattanooga, Tennessee Area'\n",
    "    'Myrtle Beach, South Carolina Area'\n",
    "    'Baton Rouge, Louisiana Area'\n",
    "    'New York, New York'\n",
    "    'San Jose, California'\n",
    "    'Greater Boston Area'\n",
    "    'Monroe, Louisiana Area'\n",
    "    'Virginia Beach, Virginia'\n",
    "    'Greater Grand Rapids, Michigan Area'\n",
    "    'Jackson, Mississippi Area'\n",
    "    'Katy, Texas'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c19b522-6e2b-44dc-b1b1-e039b5ce9940",
   "metadata": {},
   "source": [
    "Then we'll apply the city boundary data to each city, using the data from [this repo](https://github.com/drei01/geojson-world-cities/tree/master)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d5ff9d-290e-46bd-b4ef-ae62024e7f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install and load spatial extension\n",
    "dd.execute('INSTALL spatial')\n",
    "dd.execute('LOAD spatial')\n",
    "\n",
    "# load cities geojson\n",
    "rel=dd.read_json('../data/cities.geojson')\n",
    "\n",
    "# show schema of the \"rel\" relation\n",
    "dd.sql('summarize rel').select('column_name','column_type').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cc57be-49e8-4eaa-9bed-14fb52c28733",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['connection']<150].count().iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20971800-af7c-4f60-ab47-8565399997d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['connection']>150].count().iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dee1044-964c-46b2-83bf-2a3a36f4a5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{df[df['connection']<150].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befbdb46-877a-45b5-8aaa-e81933f17ad7",
   "metadata": {},
   "source": [
    "Most observations have more than 500 connections."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apziva",
   "language": "python",
   "name": "apziva"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
